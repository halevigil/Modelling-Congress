{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all committee names\n",
    "import pandas as pd\n",
    "import re\n",
    "datasets = [f\"data/US/{term*2+2009-222}-{term*2+2010-222}_{term}th_Congress/csv/bills.csv\" for term in range(111,120)]\n",
    "bills_df=pd.concat([pd.read_csv(dataset) for dataset in datasets])\n",
    "committees=[committee for committee in set(bills_df[\"committee\"]) if type(committee)==str and committee !=\" \" and committee!=\"\"]\n",
    "committee_spellings={committee:[committee] for committee in committees}\n",
    "committee_search_item={}\n",
    "for committee in committees:\n",
    "  committee_spellings[committee]=[]\n",
    "  if not re.search(\"committee\",committee.lower()):\n",
    "    committee_spellings[committee].append(committee + \" Committee\")\n",
    "    committee_spellings[committee].append(\"Committee on \"+committee)\n",
    "    committee_spellings[committee].append(\"Committee on the \"+committee)\n",
    "    if re.search(\"Senate\",committee):\n",
    "      committee_spellings[committee].append(re.sub(\"Senate \",\"\",committee)+ \" Committee\")\n",
    "      committee_spellings[committee].append(\"Senate Committee on the \"+re.sub(\"Senate \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"Senate Committee on \"+re.sub(\"House \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"Committee on the \"+re.sub(\"Senate \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"Committee on \"+re.sub(\"Senate \",\"\",committee))\n",
    "    if re.search(\"House\",committee):\n",
    "      committee_spellings[committee].append(re.sub(\"House \",\"\",committee)+ \" Committee\")\n",
    "      committee_spellings[committee].append(\"House Committee on the \"+re.sub(\"House \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"House Committee on \"+re.sub(\"House \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"Committee on the \"+re.sub(\"House \",\"\",committee))\n",
    "      committee_spellings[committee].append(\"Committee on \"+re.sub(\"House \",\"\",committee))\n",
    "  committee_spellings[committee].append(committee)\n",
    "  if re.search(\"(House )|(Senate )\",committee):\n",
    "    committee_spellings[committee].append(re.sub(\"(House )|(Senate )\",\"\",committee))\n",
    "  if re.search(\"committee\",committee):\n",
    "      committee_spellings[committee].append(re.sub(\"(Subcommittee on )|(Subcommittee for )|(Subcommittee )|( Subcommittee)|(Committee on )|(Committee for )|( Committee)|(Committee )\",\"\",committee))\n",
    "  if re.search(\"committee\",committee) and re.search(\"(House )|(Senate )\",committee):\n",
    "      committee_spellings[committee].append(re.sub(\"(Subcommittee on )|(Subcommittee for )|(Subcommittee )|( Subcommittee)|(Committee on )|(Committee for )|( Committee)|(Committee )|(Senate )|(House )\",\"\",committee))\n",
    "  committee_search_item[committee]=re.sub(\"(Subcommittee on )|(Subcommittee for )|(Subcommittee )|( Subcommittee)|(Committee on )|(Committee for )|( Committee)|(Committee )|(Senate )|(House )\",\"\",committee)\n",
    "#   committees.append(\"Committee on \"+committee)\n",
    "\n",
    "display(committee_spellings)\n",
    "display(committee_search_item)\n",
    "# for committee in committees:\n",
    "#   print(committee)\n",
    "\n",
    "#   committees.append(\"Committee on \"+committee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each action to the committee[s] it is in\n",
    "import json\n",
    "datasets = [f\"data/US/{term*2+2009-222}-{term*2+2010-222}_{term}th_Congress/csv/history.csv\" for term in range(111,120)]\n",
    "history_df=pd.concat([pd.read_csv(dataset) for dataset in datasets])\n",
    "actions = list(set(history_df[\"action\"]))\n",
    "def actions_to_committees(actions):\n",
    "  action_committees_map={}\n",
    "  for action in actions:\n",
    "    action_committees_map[action]=[]\n",
    "    for committee in committees:\n",
    "      if re.search(committee_search_item[committee],action):\n",
    "        action_committees_map[action].append(committee)\n",
    "  return action_committees_map\n",
    "action_committees_map=actions_to_committees(actions)\n",
    "# display([x for x in action_committees_map.items() if len(x[1])>0])\n",
    "json.dump(action_committees_map,open(\"./outputs/action_committees_map.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "action_committees_map=json.load(open(\"./outputs/action_committees_map.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for comparing two actions to see similarity\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "# action_process_memo={}\n",
    "def topsort(g):\n",
    "  out=[]\n",
    "  visited=set()\n",
    "  def explore(node):\n",
    "    if node not in visited:\n",
    "      for neighbor in g[node]:\n",
    "        explore(neighbor)\n",
    "      out.append(node)\n",
    "      visited.add(node)\n",
    "  for node in g:\n",
    "    explore(node)\n",
    "  return list(reversed(out))\n",
    "def longest_path(g):\n",
    "  topsorting = topsort(g)\n",
    "  longest_path_node={}\n",
    "  for node in topsorting:\n",
    "    if node not in longest_path_node:\n",
    "      longest_path_node[node]=0\n",
    "    for neighbor in g[node]:\n",
    "      if neighbor not in longest_path_node:\n",
    "        longest_path_node[neighbor]=0\n",
    "      longest_path_node[neighbor]=max(longest_path_node[neighbor],longest_path_node[node]+1)\n",
    "  return max([longest_path_node[x] for x in longest_path_node]) if len(longest_path_node)!=0 else 0\n",
    "\n",
    "import itertools\n",
    "action_process_map={}\n",
    "def process_action(action):\n",
    "  if action in action_process_map:\n",
    "    return action_process_map[action]\n",
    "  action=action.lower()\n",
    "  action=re.sub(\"committees\",\"committee\",action)\n",
    "  committees=[committee for committee in committee_search_item if re.search(committee_search_item[committee].lower(),action) and not re.search(\"subcommittee\",action.lower())]\n",
    "  subcommittees=[committee for committee in committee_search_item if re.search(committee_search_item[committee].lower(),action) and re.search(\"subcommittee\",action.lower())]\n",
    "  if len(committees)>0:\n",
    "    committee_spellings_regex=\"|\".join([\"(\"+\")|(\".join(committee_spellings[committee])+\")\" for committee in committees]).lower()\n",
    "    action = re.sub(committee_spellings_regex,\"committee\",action)\n",
    "  if len(subcommittees)>0:\n",
    "    committee_spellings_regex=\"|\".join([\"(\"+\")|(\".join(committee_spellings[committee])+\")\" for committee in subcommittees]).lower()\n",
    "    action = re.sub(committee_spellings_regex,\"subcommittee\",action)\n",
    "  action=re.sub(r\"\\,|\\.|\\-\",\" \",action)\n",
    "  action=re.sub(r\"[0-9]\",\"\",action)\n",
    "  action=re.sub(r\" +\",\" \",action)\n",
    "  action = re.sub(r'\\b(mr|mrs|ms|senator|representative) \\w+\\s', 'representative ',action)\n",
    "  action = re.sub(r'(\\w+ hour)|(\\w+ minutes)', 'time',action)\n",
    "  action = re.sub(r'\\(.*?\\)', '',action)\n",
    "  action=re.sub(r\" +\",\" \",action)\n",
    "  action_process_map[action]=action\n",
    "  return action\n",
    "# def rename(action):\n",
    "#   # if action in action_process_map:\n",
    "#   #   return action_process_map[action]\n",
    "#   # action=action.lower()\n",
    "#   # action=re.sub(\"committees\",\"committee\",action)\n",
    "#   # committees=[committee for committee in committee_search_item if re.search(committee_search_item[committee].lower(),action) and not re.search(\"subcommittee\",action.lower())]\n",
    "#   # subcommittees=[committee for committee in committee_search_item if re.search(committee_search_item[committee].lower(),action) and re.search(\"subcommittee\",action.lower())]\n",
    "#   # if len(committees)>0:\n",
    "#   #   committee_spellings_regex=\"|\".join([\"(\"+\")|(\".join(committee_spellings[committee])+\")\" for committee in committees]).lower()\n",
    "#   #   action = re.sub(committee_spellings_regex,\"the committee\",action)\n",
    "#   # if len(subcommittees)>0:\n",
    "#   #   committee_spellings_regex=\"|\".join([\"(\"+\")|(\".join(committee_spellings[committee])+\")\" for committee in subcommittees]).lower()\n",
    "#   #   action = re.sub(committee_spellings_regex,\"the subcommittee\",action)\n",
    "#   # action=re.sub()\n",
    "#   # action=re.sub(r\"\\,|\\.|\\-\",\" \",action)\n",
    "#   # action=re.sub(r\"[0-9]\",\"\",action)\n",
    "#   # action=re.sub(r\" +\",\" \",action)\n",
    "#   # action = re.sub(r'\\b(mr|mrs|ms|senator|representative) \\w+\\s', 'representative ',action)\n",
    "#   # action = re.sub(r'(\\w+ hour)|(\\w+ minutes)', 'time',action)\n",
    "#   action = re.sub(r'\\(.*?\\)', '',action)\n",
    "#   # action=re.sub(r\" +\",\" \",action)\n",
    "#   # action_process_map[action]=action\n",
    "#   return action\n",
    "action_process_split_map={}\n",
    "def process_split_action(action):\n",
    "  if action in action_process_split_map:\n",
    "    return action_process_split_map[action]\n",
    "  processed_action=process_action(action)\n",
    "  processed_split_action=processed_action.split(\" \")\n",
    "  processed_split_action=[x for x in processed_split_action if x!=\"\"]\n",
    "  action_process_split_map[action]=processed_split_action\n",
    "  return processed_split_action\n",
    "\n",
    "def longest_common_subsequence_old(sentence1,sentence2):\n",
    "  if len(sentence1)==0 or len(sentence2)==0:\n",
    "    return 0\n",
    "  matches=[]\n",
    "  for i1,word1 in enumerate(sentence1):\n",
    "    for i2,word2 in enumerate(sentence2):\n",
    "      if word1==word2:\n",
    "        matches.append((i1,i2))\n",
    "  if len(matches)==0:\n",
    "    return 0\n",
    "  g = {}\n",
    "  for match1 in matches:\n",
    "    if match1 not in g:\n",
    "      g[match1]=[]\n",
    "    for match2 in matches:\n",
    "      if match2 not in g:\n",
    "        g[match2]=[]\n",
    "      if match1[0]<match2[0] and match1[1]<match2[1]:\n",
    "        g[match1].append(match2)\n",
    "  return longest_path(g)+1\n",
    "def edit_distance(l1,l2):\n",
    "  dp=np.empty((len(l2)+1,len(l1)+1))\n",
    "  dp[0]=range(len(l1)+1)\n",
    "  dp[:,0]=range(len(l2)+1)\n",
    "  for i in range(1,len(l2)+1):\n",
    "    for j in range(1,len(l1)+1):\n",
    "      dp[i,j]=min(dp[i][j-1]+1,dp[i-1][j]+1,dp[i-1][j-1] if l1[j-1]==l2[i-1] else dp[i-1][j-1]+1)\n",
    "  return dp[-1,-1]\n",
    "def longest_common_subsequence(l1, l2):\n",
    "  # Helper function to calculate edit distance without substitutions allowed\n",
    "  def edit_distance_no_subs(l1, l2):\n",
    "    # Create dp matrix with size (len(l2)+1) x (len(l1)+1)\n",
    "    dp = np.empty((len(l2)+1, len(l1)+1))\n",
    "    # Initialize first row and column\n",
    "    dp[0] = range(len(l1)+1)\n",
    "    dp[:,0] = range(len(l2)+1)\n",
    "    # Set infinity value for substitutions\n",
    "    inf = float('inf')  # Use float('inf') instead of len(l1)*len(l2)\n",
    "    \n",
    "    # Fill dp matrix\n",
    "    for i in range(1, len(l2)+1):\n",
    "      for j in range(1, len(l1)+1):\n",
    "        # If characters match, take diagonal value\n",
    "        # If not, take minimum of insert/delete plus 1\n",
    "        # Substitutions are not allowed (inf cost)\n",
    "        dp[i,j] = min(\n",
    "          dp[i][j-1] + 1,  # deletion\n",
    "          dp[i-1][j] + 1,  # insertion\n",
    "          dp[i-1][j-1] if l1[j-1] == l2[i-1] else inf  # match or substitution\n",
    "        )\n",
    "    return dp[-1][-1]\n",
    "\n",
    "  # Handle empty sequences\n",
    "  if not l1 or not l2:\n",
    "    return 0\n",
    "    \n",
    "  # LCS length = (len(l1) + len(l2) - edit_distance_no_subs) / 2\n",
    "  # Since each non-matching character requires one insertion and one deletion\n",
    "  distance = edit_distance_no_subs(l1, l2)\n",
    "  return (len(l1) + len(l2) - distance) // 2\n",
    "\n",
    "def test_edit_distance():\n",
    "  # Test empty strings\n",
    "  assert edit_distance([], []) == 0\n",
    "  # Test one empty string\n",
    "  assert edit_distance([], ['a']) == 1\n",
    "  assert edit_distance(['a'], []) == 1\n",
    "  # Test single character difference\n",
    "  assert edit_distance(['a'], ['b']) == 1\n",
    "  # Test same strings\n",
    "  assert edit_distance(['a', 'b', 'c'], ['a', 'b', 'c']) == 0\n",
    "  # Test insertion\n",
    "  assert edit_distance(['a', 'c'], ['a', 'b', 'c']) == 1\n",
    "  # Test deletion\n",
    "  assert edit_distance(['a', 'b', 'c'], ['a', 'c']) == 1\n",
    "  # Test substitution\n",
    "  assert edit_distance(['a', 'b', 'c'], ['a', 'd', 'c']) == 1\n",
    "  # Test multiple operations\n",
    "  assert edit_distance(['a', 'b'], ['c', 'd']) == 2\n",
    "\n",
    "# test_edit_distance()\n",
    "mustmatch_regexes=[\"subcommittee\"]\n",
    "def similar_words(action1,action2,threshold):\n",
    "  for regex in mustmatch_regexes:\n",
    "    if not (bool(re.search(regex,action1.lower() if regex.islower() else action1))==bool(re.search(regex,action2.lower() if regex.islower() else action2))):\n",
    "      return False\n",
    "  action1=process_split_action(action1)\n",
    "  action2=process_split_action(action2)\n",
    "  length=max(len(action1),len(action2))\n",
    "  return abs(len(action1)-len(action2))<threshold*length and edit_distance_below(action1,action2,threshold*length)\n",
    "def similar_string(action1,action2,threshold):\n",
    "  action1=process_action(action1)\n",
    "  action2=process_action(action2)\n",
    "\n",
    "  for regex in mustmatch_regexes:\n",
    "    if not (bool(re.search(regex,action1))==bool(re.search(regex,action2))):\n",
    "      return False\n",
    "  length=max(len(action1),len(action2))\n",
    "  return abs(len(action1)-len(action2))<threshold*length and edit_distance_below(action1,action2,threshold*length)\n",
    "\n",
    "\n",
    "# Test cases\n",
    "# print(\"Test 1:\", subsequence_similarity(\"hi my name is Bob\", \"hi Bob\") == 2)  # Should match \"hi\" and \"Bob\"\n",
    "# print(\"Test 2:\", subsequence_similarity(\"a b c\", \"a c b\") == 2)  # Should match \"a\" and either \"b\" or \"c\"\n",
    "# print(\"Test 3:\", subsequence_similarity(\"x y z\", \"a b c\") == 0)  # No common subsequence except single words\n",
    "# print(\"Test 4:\", subsequence_similarity(\"\", \" \") == 0)  # Empty strings\n",
    "# print(\"Test 5:\", subsequence_similarity(\"hello world\", \"hello there world\") == 2)  # \"hello\" and \"world\"\n",
    "\n",
    "# Checks if the edit distance between l1 and l2 is below threshold*max(len(l1),len(l2))\n",
    "def prefix_sum(l):\n",
    "  s=0\n",
    "  out=[]\n",
    "  for e in l:\n",
    "    s+=e\n",
    "    out.append(s)\n",
    "  return out\n",
    "def postfix_sum(l):\n",
    "  s=0\n",
    "  out=[]\n",
    "  for e in reversed(l):\n",
    "    s+=e\n",
    "    out.append(s)\n",
    "  return list(reversed(out))\n",
    "def edit_distance_below(l1,l2,threshold):\n",
    "  if abs(len(l1)-len(l2))>threshold:\n",
    "    return False\n",
    "  dp=np.empty((len(l2)+1,len(l1)+1))\n",
    "  dp[0]=range(len(l1)+1)\n",
    "  dp[:,0]=range(len(l2)+1)\n",
    "  min_dist=1\n",
    "  max_num=max(len(l2),len(l1))+1\n",
    "  for i in range(2*len(l2)+2):\n",
    "    min_dist_last=min_dist\n",
    "    min_dist=max_num\n",
    "    for j in range(max(i-len(l1)-1,0),min(i+1,len(l2)+1)):\n",
    "      col=i-j\n",
    "      row=j\n",
    "      if row > len(l2) or col > len(l1):\n",
    "        continue\n",
    "      if row>0 and col>0:\n",
    "        dp[row,col]=min(dp[row][col-1]+1,dp[row-1][col]+1,dp[row-1][col-1] if l2[row-1]==l1[col-1] else dp[row-1][col-1]+1)\n",
    "      if dp[row,col]<min_dist:\n",
    "        min_dist=dp[row,col]\n",
    "    if min_dist<max_num and min(min_dist,min_dist_last)>threshold:\n",
    "      return False\n",
    "  return dp[-1,-1]<=threshold\n",
    "def test_edit_distance_below():\n",
    "  # Test cases for edit_distance_below function\n",
    "  # Test empty strings\n",
    "  assert edit_distance_below([], [], 0) == True, \"Failed on empty strings\"\n",
    "  # Test one empty string\n",
    "  assert edit_distance_below([], ['a'], 0.5) == False, \"Failed on one empty string\"\n",
    "  assert edit_distance_below(['a'], [], 0.5) == False, \"Failed on one empty string\"\n",
    "  # Test single character difference\n",
    "  assert edit_distance_below(['a'], ['b'], 1.0) == True, \"Failed on single character difference\"\n",
    "  assert edit_distance_below(['a'], ['b'], 0.5) == False, \"Failed on single character difference\"\n",
    "  # Test same strings\n",
    "  assert edit_distance_below(['a', 'b', 'c'], ['a', 'b', 'c'], 1.5) == True, \"Failed on same strings\"\n",
    "  # Test insertion\n",
    "  assert edit_distance_below(['a', 'c'], ['a', 'b', 'c'], 1.5) == True, \"Failed on insertion\"\n",
    "  assert edit_distance_below(['a', 'c'], ['a', 'b', 'c'], 0.9) == False, \"Failed on insertion\"\n",
    "  # Test deletion\n",
    "  assert edit_distance_below(['a', 'b', 'c'], ['a', 'c'], 1.5) == True, \"Failed on deletion\"\n",
    "  assert edit_distance_below(['a', 'b', 'c'], ['a', 'c'], 0.9) == False, \"Failed on deletion\"\n",
    "  # Test substitution\n",
    "  assert edit_distance_below(['a', 'b', 'c'], ['a', 'd', 'c'], 1.5) == True, \"Failed on substitution\"\n",
    "  assert edit_distance_below(['a', 'b', 'c'], ['a', 'd', 'c'], 0.9) == False, \"Failed on substitution\"\n",
    "  # Test multiple operations\n",
    "  assert edit_distance_below(['a', 'b'], ['c', 'd'], 2) == True, \"Failed on multiple operations\"\n",
    "  assert edit_distance_below(['a', 'b'], ['c', 'd'], 1) == False, \"Failed on multiple operations\"\n",
    "  # Test longer strings\n",
    "  assert edit_distance_below(['a', 'b', 'c', 'd'], ['a', 'x', 'c', 'y'], 2) == True, \"Failed on longer strings\"\n",
    "  assert edit_distance_below(['a', 'b', 'c', 'd'], ['a', 'x', 'c', 'y'], 1.3) == False, \"Failed on longer strings\"\n",
    "\n",
    "  # Run the test cases\n",
    "test_edit_distance_below()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to process all the actions ahead of time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "datasets = [f\"data/US/{term*2+2009-222}-{term*2+2010-222}_{term}th_Congress/csv/history.csv\" for term in range(111,120)]\n",
    "history_df=pd.concat([pd.read_csv(dataset) for dataset in datasets])\n",
    "actions = list(set(history_df[\"action\"]))\n",
    "for action in actions:\n",
    "  process_split_action(action,action_process_map) # build up memo \n",
    "json.dump(action_process_map,open(\"./outputs/07-23/action_process_map.json\",\"w\"),indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_buckets_f(action):\n",
    "  if re.search(r\"^h\\.amdt\\.[0-9]*? amendment \\(.*?\\) in the nature of a substitute offered by\",action.lower()):\n",
    "    return \"H.Amdt. in the nature of a substitute offered by\"\n",
    "  if re.search(r\"^h\\.amdt\\.[0-9]*? amendment \\(.*?\\) offered by\",action.lower()):\n",
    "    return \"H.Amdt. offered by\"\n",
    "  if re.search(r\"^s\\.amdt\\.[0-9]*? amendment sa [0-9]*? proposed by\",action.lower()):\n",
    "    return \"S.Amdt. offered by\"\n",
    "  if re.search(r\"the.*? house.*? proceeded.*? with.*? of debate.*? on.*? the.*? amendment\",action.lower()):\n",
    "    return \"DEBATE - The House proceeded with 10 minutes of debate on the Broun (GA) motion to recommit with instructions\"\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(special_buckets_f(\"Floor summary: DEBATE - The House proceeded with 10 minutes of debate on the Delaney motion to recommit with instructions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(process_action(\"H.AMDT.1 Amendment (A001) offered by Mr. Becerra. (consideration: CR H6; text: CR H6)Amendment nominated Democrat candidates for Officers of the House.\"))\n",
    "print(process_action(\"H.AMDT.100 Amendment (A011) offered by Mr. Minnick. (consideration: CR H5029; text: CR H5029)Amendment provides that the amount of a balance following a notice of a rate increase would be protected from the rate of increase as of the 7-day mark instead of the 14-day mark.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "buckets_saved={}\n",
    "def bucket_actions(actions,similar,special_bucket_f = lambda x:None,bucket_names_f=lambda x:x):\n",
    "  special_buckets=defaultdict(list)\n",
    "  bucket_list=[]\n",
    "  \n",
    "  for i,action in enumerate(actions):\n",
    "    bucketed=False\n",
    "    if action_special_bucket:=special_bucket_f(action):\n",
    "      special_buckets[action_special_bucket].append(action)\n",
    "      bucketed=True\n",
    "    else:\n",
    "      for bucket in reversed(bucket_list):\n",
    "        if similar(bucket[0],action):\n",
    "          bucket.append(action)\n",
    "          bucketed=True\n",
    "          break\n",
    "    if i%1000==0:\n",
    "      print(i)\n",
    "    if not bucketed:\n",
    "      print(action)\n",
    "      bucket_list.append([action])\n",
    "  buckets = {bucket_names_f(bucket[0]):bucket for bucket in bucket_list}\n",
    "  buckets.update(special_buckets)\n",
    "  buckets_saved.update(buckets)\n",
    "  # bucket_list_saved.append(bucket_list)\n",
    "  return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket actions\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# actions=\n",
    "# actions = [sentence_split(action) for action in history_df[\"action\"]]\n",
    "\n",
    "# buckets=bucket_actions(lambda action1,action2:similar_string(action1,action2,1/7  ),special_bucket_f=special_buckets_f,bucket_names_f=lambda x:process_action(x))\n",
    "datasets = [f\"data/US/{term*2+2009-222}-{term*2+2010-222}_{term}th_Congress/csv/history.csv\" for term in range(111,120)]\n",
    "history_df=pd.concat([pd.read_csv(dataset) for dataset in datasets])\n",
    "actions = sorted(list(set(history_df[\"action\"])))\n",
    "buckets=bucket_actions(actions,lambda action1,action2:similar_string(action1,action2,1/7),special_bucket_f=special_buckets_f)\n",
    "bucket_names=list(buckets.keys())\n",
    "# buckets=bucket_actions(lambda action1,action2:similar_words(action1,action2,1/4),special_bucket_f=special_buckets_f)\n",
    "  \n",
    "\n",
    "# buckets_raw=[]\n",
    "# special_buckets_raw=[[],[],[]]\n",
    "# actions = \n",
    "# for i,action in enumerate(actions):\n",
    "#   bucketed=False\n",
    "#   # if re.search(r\"^debate - the house proceeded with 10 minutes of debate on the .*?motion to recommit\",action[1].lower()):\n",
    "#   #   special_buckets_raw[3].append(action)\n",
    "#   #   continue\n",
    "#   for bucket in reversed(buckets_raw):\n",
    "#     # if action[0]==bucket[0][0]:\n",
    "#     #   bucket.append(action)\n",
    "#     #   bucketed=True\n",
    "#     #   break\n",
    "#     if abs(len(action[0])-len(bucket[0][0]))<1/3*max(len(bucket[0][0]),len(action[0])) and subsequence_similarity(action[0],bucket[0][0])>=max(len(action[0])*2/3, len(bucket[0][0])*2/3):\n",
    "#       # print(action)\n",
    "#       bucket.append(action)\n",
    "#       bucketed=True\n",
    "#       break\n",
    "# buckets_raw.extend(special_buckets_raw)\n",
    "# buckets = [[action[1] for action in bucket if type(action[1])==str] for bucket in buckets_raw]\n",
    "# display(buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"outputs/buckets_after_refinement_08-01.json\",\"r\") as file:\n",
    "  buckets_refined=json.load(file)\n",
    "bucket_names_refined=sorted(list(buckets_refined.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(buckets_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"outputs/buckets_08-01_manual-llm.json\",\"r\") as file:\n",
    "  buckets_refined=json.load(file)\n",
    "bucket_names_refined=sorted(list(buckets_refined.keys()))\n",
    "bucket_names_refined_combined = bucket_actions(bucket_names_refined,lambda name1, name2: edit_distance_below(name1,name2,1/7*max(len(name1),len(name2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets_refined_combined=bucket_names_refined_combined\n",
    "buckets_refined_combined=defaultdict(list)\n",
    "\n",
    "for name in bucket_names_refined_combined:\n",
    "  for name2 in bucket_names_refined_combined[name]:\n",
    "    buckets_refined_combined[name].extend(buckets_refined[name2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sum(len(x) for x in buckets_refined_combined.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/buckets_08-04_manual-llm-manual.json\",\"w\") as file:\n",
    "  json.dump(buckets_refined_combined,file,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sorted(bucket_names_\n",
    "                   ):\n",
    "  print(len(buckets_refined_combined[name]),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def make_extra_buckets(actions,f):\n",
    "  buckets=defaultdict(list)\n",
    "  for action in actions:\n",
    "    for bucket in f(action):\n",
    "      buckets[bucket].append(action)\n",
    "  return dict(buckets)\n",
    "regexes=[r\"^All points of consideration against consideration.*? are waived\",\\\n",
    "         r\"^ANNOUNCEMENT\",r\"^APPOINTMENT OF CONFEREE\",r\"^APPOINTMENT OF.*? CONFEREE\",\\\n",
    "          r\"^forwarded by subcommittee to full committee\",r\"^GENERAL DEBATE\",r\"^Introduced in the Senate\",\\\n",
    "          r\"^MOMENT OF SILENCE\",r\"^Motion by \\[SENATOR\\] to (commit|refer) to\",r\"^Motion (by \\[SENATOR\\] )?to concur\",\\\n",
    "          r\"^Motion by \\[SENATOR\\] to instruct\",r\"^Motion by \\[SENATOR\\] to reconsider\",r\"^Motion to disagree\",\\\n",
    "          r\"^Motion to discharge\",r\"^Motion to proceed to consideration\",r\"^Motion to table the motion\",\n",
    "          r\"^Motion to waive\",r\"^NOTIFICATION OF INTENT\",\"^ORDER OF BUSINESS\",\"^ORDER OF PROCEDURE\",\n",
    "          r\"^On agreeing to the resolution\",r\"On agreeing to the \\[REPRESENTATIVE\\] amendment\",\\\n",
    "          r\"On motion that the House (dis)?agree to the Senate amendment\",\\\n",
    "          r\"On motion that the House agree with an amendment\",\\\n",
    "          r\"On motion that the House (dis)?agree\",\n",
    "          r\"On motion that the House instruct conferees\",\n",
    "          r\"^On motion (that the House |to )suspend the rules\",r\"^On passage\",r\"^On ordering the previous question\",\n",
    "          r\"^On questioning of consideration\",r\"^Ordered to be [r|R]eported\",r\"^point of order\",\n",
    "          r\"^POSTPONED CONSIDERATION OF VETO MESSAGE\",r\"^POSTPONED PROCEEDING\",r\"POSTPONED ROLL CALL VOTE\",\n",
    "          r\"^Passed Senate\",r\"^Previous question shall be considered as ordered\",\\\n",
    "          r\"Previous question shall be considered as ordered\",\\\n",
    "          r\"^Provides for consideration of \\[BILL\",r\"^Provides for consideration of the Senate Amendment\",\\\n",
    "          r\"^Provides for consideration\", r\"^Provides for( \\w+)? \\[TIME\\] of.*? debate\",\\\n",
    "          r\"^Pursuant to \\[RESOLUTION\\]\", r\"^Pursuant to a previous( \\w+)? order\", r\"Pursuant to clause\",\\\n",
    "          r\"^Pursuant to the order of\",\\\n",
    "          r\"^proceeded with.*? debate\",r\"^Pursuant to the provisions of \\[RESOLUTION\\]\",r\"^QUESTION OF CONSIDERATION\",\\\n",
    "          r\"^QUESTION OF CONSIDERATION\",r\"^QUESTION OF THE PRIVILEGES OF THE HOUSE\",r\"^Received in the Senate\",\\\n",
    "          r\"^received in the senate[\\,\\.] read\",\\\n",
    "          r\"^Referred\",r\"^Resolution agreed to in Senate\",r\"Resolution provides for( \\w+)? \\[TIME\\] of general debate\",\\\n",
    "          r\"(Rule|Resolution) provides for( \\w+)? \\[TIME\\] of general debate\",\"debate\",\\\n",
    "          r\"^Resolution provides for consideration of( \\w+)? \\[BILL\",r\"^Resolving differences\",r\"^Rule provides for consideration\",\\\n",
    "          r\"^Rules Committee Resolution\",r\"^Ruling of the Chair\",r\"^Second cloture\", r\"See( \\w+)\\[BILL\\] \",\n",
    "          r\"^Senate Committee.*? discharged\",r\"^Senate agreed to.*? amendment\",r\"^Senate agreed to conference report\",\\\n",
    "            r\"Senate agreed to\",r\"Senate appointed conferee\",r\"Senate concurred in\", r\"Senate disagree. to.*? House amendment\",\n",
    "            r\"Senate insists on its amendment\",r\"^Senate passed companion measure\", r\"Senate returned papers\", \n",
    "            r\"Senate vitiated previous\",\n",
    "            r\"Star Print ordered\",r\"The Chair announced\",r\"^The Chair\",\"postponed\",r\"The Committee of the Whole\",\n",
    "            \"The Committee of the Whole proceeded\",\n",
    "            r\"The Committee rose informally\",r\"The House proceeded with.*? \\[TIME\\] of debate\",\n",
    "            r\"The House resolved into Committee of the Whole\",\n",
    "            r\"The Speaker appointed (additional )?conferees\",r\"^The amendment.*? printed\",r\"^The amendment.*? recommended by\",\n",
    "            r\"The committee.*? (amendment|substitute) agreed to\",r\"^The previous question.*? was ordered\",\n",
    "            r\"The (resolution|rule) makes in order\",\n",
    "            r\"The (resolution|rule) provides for.*? of debate\",\n",
    "            r\"The (resolution|rule).*? provides for (the )?(further )?consideration of\", \n",
    "            r\"The (resolution|rule) provides that an amendment.*? shall be considered as adopted\",\n",
    "            r\"The (resolution|rule) waives all points of order\",r\"The resolution waives clause 6\",\n",
    "            r\"The (resolution|rule) provides that the bills shall be considered as read\",\n",
    "            r\"The (resolution|rule) provides.*? motion.? to recommit per bill\"\n",
    "            r\"The (resolution|rule) provides that an amendment.*? shall be considered as an original bill\",\n",
    "            r\"^UNANIMOUS CONSENT\",r\"^UNFINISHED BUSINESS\",\"60 votes\", \"five.minute rule\",\n",
    "            r\"Upon reconsideration,.*? cloture\",r\"^VACATING DEMAND\",r\"^VACATING PROCEEDINGS\",r\"^Veto message\",r\"^WORDS TAKEN DOWN\",\n",
    "            r\"Without objection, the Chair laid\",r\"point of order\",r\"\\[amendment agreed to in Senate\\]\",r\"\\[amendment.*? modified]\",\n",
    "            r\"amendments? offered by\",r\"amendment.*?\\b\\w+\\b(?<!\\bnot) agreed to\",r\"amendment.*? not agreed to\",r\"\\[AMENDMENT\\].*? failed\",\n",
    "            r\"\\[AMENDMENT\\] fell\",\n",
    "            r\"\\[AMENDMENT\\].*? withdrawn\",r\"\\[AMENDMENT\\] modified\",r\"\\[AMENDMENT\\] motion.*? to reconsider the vote\",\n",
    "            r\"motion to table amendment\",r\"motion to waive.*? budgetary discipline\",\n",
    "            r\"\\[AMENDMENT\\] raised a point of order\",\n",
    "            r\"\\[AMENDMENT\\] referred to\",r\"\\[AMENDMENT\\] second cloture\",\n",
    "            \"Hearings held.\",r\"\\[COMMITTEE\\] discharged\",r\"\\[COMMITTEE\\].*? consideration held.\",\n",
    "            r\"\\[COMMITTEE\\].*? reported by \\[SENATOR\\]\", r\"\\[REPRESENTATIVE\\] asked unanimous consent\",r\"\\[BILLS\\]\",r\"\\[RESOLUTION\\]\"\n",
    "            r\"\\[REPRESENTATIVE\\] appealed the ruling of the (c|C)hair\",r\"^\\[COMMITTEE\\]\",r\"^\\[REPRESENTATIVE\\]\",\n",
    "            r\"^\\[AMENDMENT\\]\",r\"\\[RESOLUTIONS\\]\",r\"\\[LAW\\]\",r\"\\[BILL\\]\",r\"\\[RESOLUTIONS\\]\",r\"\\[RULE\\]\"\n",
    "            r\"\\[REPRESENTATIVE\\] moved that the House (agree|concur)\",\n",
    "            r\"\\[REPRESENTATIVE\\] moved that the House (agree|concur|insist|disagree)\",r\"subcommittee\",\"joint\"\n",
    "            r\"\\[REPRESENTATIVE\\] moved to table the motion\",\n",
    "            r\"\\[REPRESENTATIVE\\] raised a point of order\",\n",
    "            \"^On motion\",\"suspend the rules\",\"read twice\",\"instructions\",\"by yea-nay vote\",\n",
    "            \"withdrawn\",\"Rule\",r\"print\",\"conference report\",\n",
    "            \"committee\",\"unanimous consent\",\"voice vote\",\"cloture\",\"closed rule\",\"pursuant to\",\n",
    "            \"unfinished\",\"in the nature of a substitute\",\"waive\"]\n",
    "def unregex(regex):\n",
    "  regex=re.sub(r\"[^\\\\]*\\.\",\"\",regex)\n",
    "  regex=re.sub(r\"[^\\\\]*\\^\",\"\",regex)\n",
    "  regex=re.sub(r\"[^\\\\]*\\?\",\"\",regex)\n",
    "  regex=re.sub(r\"[^\\\\]*\\<\",\"\",regex)\n",
    "  regex=re.sub(r\"[^\\\\]*\\!\",\"\",regex)\n",
    "  regex=re.sub(r\"\\|\",\" or \",regex)\n",
    "  regex=re.sub(r\"\\\\[a-zA-Z]\",\"\",regex)\n",
    "  regex=re.sub(r\"\\\\\",\"\",regex)\n",
    "  return regex\n",
    "def most_common_words(buckets):\n",
    "  counter = Counter()\n",
    "  for bucket in buckets:\n",
    "    words=[word for word in bucket.split(\" \") if word!=\"\"]\n",
    "    for word in words:\n",
    "      counter[word]+=len(buckets[bucket])\n",
    "  return counter.most_common(1000)\n",
    "def extra_buckets_f(action):\n",
    "  out=[]\n",
    "  for regex in regexes:\n",
    "    if re.search(regex,action.lower() if regex.islower() else action):\n",
    "      out.append(regex)\n",
    "  return out\n",
    "# print(extra_buckets_f('A QUESTION OF THE PRIVILEGES OF THE HOUSE - [REPRESENTATIVE] rose to a question of the privileges of the House and submitted a privileged resolution. Upon examination of the resolution, the Chair determined that the resolution qualified.'))\n",
    "\n",
    "extra_buckets=make_extra_buckets(bucket_names_refined_combined,special_buckets_f)\n",
    "# display(different_buckets)\n",
    "\n",
    "# display(extra_buckets)\n",
    "# display(list(buckets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/extra_buckets_08-04.json\",\"w\") as file:\n",
    "  json.dump(extra_buckets,file,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_refined_combined={}\n",
    "unbucketed=[]\n",
    "for combination in bucket_names_refined_combined:\n",
    "  buckets_refined_combined[combination]=[]\n",
    "  for name in bucket_names_refined_combined[combination]:\n",
    "    if name not in buckets_refined_combined:\n",
    "      unbucketed.append(name)\n",
    "      continue\n",
    "    buckets_refined_combined[combination].extend(buckets_refined[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/buckets_08-04_manual-llm-manual.json\",\"w\") as file:\n",
    "  json.dump(buckets_refined_combined,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/buckets_08-04_manual-llm-manual.json\",\"r\") as file:\n",
    "  buckets = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bucket names\n",
    "import json\n",
    "from datetime import datetime\n",
    "with open(f\"./outputs/buckets_{datetime.now().strftime(f\"%m-%d\")}_charsim17.json\",\"w\") as file:\n",
    "  json.dump(buckets,file,indent=2)\n",
    "with open(f\"./outputs/bucket_names_{datetime.now().strftime(f\"%m-%d\")}_charsim17.txt\",\"w\") as file:\n",
    "  for name in bucket_names:\n",
    "    file.write(name)\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_buckets(fs,buckets):\n",
    "  out=defaultdict(list)\n",
    "  for bucket_name in buckets:\n",
    "    moved=False\n",
    "    for f in fs:\n",
    "      if f_bucket:= f(bucket_name):\n",
    "        out[f_bucket].extend(bucket)\n",
    "        moved=True\n",
    "        break\n",
    "    if not moved:\n",
    "      out[bucket_name].append(action)\n",
    "  out=dict(out)\n",
    "  return out\n",
    "def make_new_buckets(fs,buckets):\n",
    "  out=defaultdict(list)\n",
    "  for bucket_name in buckets:\n",
    "    for action in buckets[bucket_name]:\n",
    "      # print(bucket)\n",
    "      moved=False\n",
    "      for f in fs:\n",
    "        if f_bucket:= f(action):\n",
    "          out[f_bucket].append(action)\n",
    "          moved=True\n",
    "          break\n",
    "      if not moved:\n",
    "        out[bucket_name].append(action)\n",
    "  out=dict(out)\n",
    "  return out\n",
    "\n",
    "\n",
    "\n",
    "# buckets_manual=combine_buckets(lambda bucket:re.search(r\"^h\\.amdt\\.[0-9]*? amendment \\(.*?\\) in the nature of a substitute offered by\",bucket[0].lower()) if type(bucket)==list and len(bucket)>0 else False,buckets_manual)\n",
    "\n",
    "# buckets_manual=combine_buckets(lambda bucket:re.search(r\"^h\\.amdt\\.[0-9]*? amendment \\(.*?\\) offered by\",bucket[0].lower()) if type(bucket)==list and len(bucket)>0 else False,buckets_manual)\n",
    "# buckets_manual=combine_buckets(lambda bucket:re.search(r\"^s\\.amdt\\.[0-9]*? amendment sa [0-9]*? proposed by\",bucket[0].lower()) if type(bucket)==list and len(bucket)>0 else False,buckets_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_map={action:bucket for bucket in buckets for action in buckets_saved[bucket]}\n",
    "bucket_map={}\n",
    "for name in buckets:\n",
    "  for action in buckets[name]:\n",
    "    bucket_map[action]=name\n",
    "# display(bucket_map)\n",
    "bucket_sizes={name:0 for name in buckets}\n",
    "unbucketed=[]\n",
    "bucketed=[]\n",
    "for action in history_df[\"action\"]:\n",
    "  if action not in bucket_map:\n",
    "    unbucketed.append(action)\n",
    "    continue\n",
    "  bucketed.append(action)\n",
    "  bucket_sizes[bucket_map[action]]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "def nums_to_bars(nums):\n",
    "  counter = Counter(nums)\n",
    "  keyvals=counter.items()\n",
    "  print(sorted(keyvals))\n",
    "\n",
    "  return [key for key,val in keyvals],[val for key,val in keyvals]\n",
    "xs,heights = nums_to_bars(bucket_sizes.values())\n",
    "ax.bar(xs,heights)\n",
    "ax.loglog()\n",
    "# ax.set_ybound(0,100)\n",
    "# ax.set_xbound(0,100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_names = [bucket[0] for bucket in buckets if type(bucket)==list and len(bucket)>0]\n",
    "datasets = [f\"data/US/{term*2+2009-222}-{term*2+2010-222}_{term}th_Congress/csv/history.csv\" for term in range(111,120)]\n",
    "history_df=pd.concat([pd.read_csv(dataset) for dataset in datasets])\n",
    "history_df[\"bucket\"]=history_df[\"action\"].apply(lambda action:specific_action_to_bucket_name[action])\n",
    "llm_buckets = []\n",
    "with open(\"./outputs/bucket_names_output.jsonl\", \"r\") as file:\n",
    "  for line in file:\n",
    "    if line.strip():  # Skip empty lines\n",
    "      response = json.loads(line)\n",
    "      llm_buckets.append(response[\"response\"][\"body\"][\"output\"][0][\"content\"][0][\"text\"])\n",
    "      \n",
    "history_df[\"llm_bucket\"] = history_df[\"bucket\"].map(dict(zip(bucket_names, llm_buckets)))\n",
    "\n",
    "# Add next bill_id column to compare\n",
    "history_df[\"next_bill_id\"]=history_df[\"bill_id\"].shift(-1)\n",
    "history_df[\"next_bucket\"]=history_df[\"bucket\"].shift(-1)\n",
    "history_df[\"next_bucket\"]=history_df.apply(lambda row:row[\"next_bucket\"] if row[\"next_bill_id\"]==row[\"bill_id\"] else None,1)\n",
    "history_df[\"next_bucket_llm\"]=history_df[\"llm_bucket\"].shift(-1)\n",
    "history_df[\"next_llm_bucket\"]=history_df.apply(lambda row:row[\"next_bucket_llm\"] if row[\"next_bill_id\"]==row[\"bill_id\"] else None,1)\n",
    "\n",
    "g={}\n",
    "for bucket1 in llm_buckets:\n",
    "  g[bucket1]={}\n",
    "  for bucket2 in llm_buckets:\n",
    "    g[bucket1][bucket2]=0\n",
    "  g[bucket1][None]=0\n",
    "for i, row in history_df.iterrows():\n",
    "  g[row[\"llm_bucket\"]][row[\"next_llm_bucket\"]]+=1\n",
    "# display(g)\n",
    "\n",
    "\n",
    "\n",
    "# display(history_df)\n",
    "# for i,row in history_df.iterrows():\n",
    "#   print(row.bucket)\n",
    "# for action in history_df:\n",
    "#   history_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO05QBEL1BiZJV8jZLZO8J/",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "billanalysis-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
